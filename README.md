# The Llama 3 Herd of Models explained

## Overview and Origin

LLM, Llama, is the META’s response to OpenAI's GPT and Google's Gemini, Anthropic Claude large language models with one key difference: all the Llama models are freely available for almost anyone to use for research and commercial purposes.
According to Meta website: 
“Llama 3 is a herd of language models that natively support multilingualism, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens.”
 We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety.”

 ## What is LLM in a nutshell?
A large language model (LLM) is a type of program that can recognize and generate text, among other tasks. In a simpler term, an LLM is a program that has been fed an extremely large amount of data examples to be able to recognize and interpret human language or other types of complex data. LLMs are trained on data that has been gathered from the Internet — enormous number of gigabytes' worth of text. 

All LLMs that are developed were created and work in essentially the exact same way. 

-	All use a type of neural network that uses transformer architecture, 
-	Development ideas like pretraining and fine-tuning.

Meta Llama 3.1 with 405B, is probably the world’s largest and most capable openly available foundation model, and there is free downloadable version of OLlama that can be downloaded and installed on your machine and worked on without even having internet connectivity.

## Business Activities

* What is currently used technology and implementation ?

  According to Meta : “When a user enters a text prompt in Llama 3.1 model, it attempts to predict the most plausible follow &mdash;on text using its neural network &mdash; a cascading algorithm with billions of variables (called "parameters") that's modeled after the human brain. By assigning different weights to all the different parameters, and throwing in a small bit of randomness, Llama 3.1 can generate incredibly human-like responses. “

Llama 3.1 offers 3 models, each tailored to different needs within the generative AI space:

* Llama 3.1 8B
  
  8 billion parameter variant&mdash; perfect for environments where you need quick, efficient performance without a ton of resources such as text summarization, text classification, sentiment analysis, and language translation requiring low-latency inferencing. Usually used in chatbots or basic content creation. 

* Llama 3.1 70B

70 billion parameter model- used for more complex tasks like advanced conversational agents and detailed content generation.
This model is tailored towards more complex applications requiring much deeper language understanding, such as advanced conversational bots, detailed content generation, and sophisticated analysis tasks.
Accuracy and contextual awareness are significantly higher, while maintaining manageable computational requirements. 

* Llama 3.1  405B

  405 billion parameter model&mdash; used for big tasks such as large-scale data analysis, high&mdash; precision language translation, and delicate content generation.
This model delivers unparalleled performance and accuracy for the most demanding AI applications.


## Model Architecture

According to Meta web site, training Llama 3.1 405B on over 15 trillion tokens was a major challenge:

“To enable training runs at this scale and achieve the results we have in a reasonable amount of time, we significantly optimized our full training stack and pushed our model training to over 16 thousand H100 GPUs, making the 405B the first Llama model trained at this scale.”

Meta gathered training data from publicly available sources like [Common Crawl](https://commoncrawl.org/) (an archive of billions of webpages), [Wikipedia](https://www.wikipedia.org/), and public domain books from [Project Gutenberg](https://www.gutenberg.org/), and the rest was synthetic data already generated by previous models. (None of the data is Meta user data.)

Underlying technology:
![image](https://github.com/user-attachments/assets/e41d086c-8608-467d-9232-8172560a9a19)

Llama 3.1 follows a standard Transformer architecture to its predecessors(Llama and Llama 2).
1.	Input Text Tokens: The process begins with text input, which is broken down into individual tokens (substrings with specific meanings).
2.	Token Embeddings: Each token is converted into a numerical representation (embedding) that captures its semantic and syntactic information.
3.	Self-Attention Layers: This is where the model shines. Self-attention layers analyze the relationships between different parts of the input sequence, helping the model understand context and dependencies.
4.	Feedforward Neural Networks: These networks process the information from the self-attention layers, extracting deeper patterns and features.
5.	Decoder: The decoder takes the processed information and generates the output text, one token at a time.


* What specific problem is the company or project trying to solve?
  
According to Meta, latest Llama model improved both the quantity and quality of the data used for pre- and post-training. These improvements include the development of more careful pre-processing and curation pipelines for pre-training data, such as reinforcement learning with human feedback (RLHF), to optimize the model for safe and helpful responses. Meta has also developed Llama Guard, Prompt Guard, and Llama Code Shield, three safety models designed to prevent Llama models from running harmful prompts or generating insecure computer code. Also META developed more rigorous quality assurance, and filtering approaches for post-training .

* What solution does this company offer?
  #####  “Openness drives innovation”
Unlike closed models, Llama models are available to download. Companies can fully customize the models for their needs and applications, train on new proprietary datasets, and conduct additional fine-tuning tailored to the business needs.


## Llama vs. GPT, Gemini,Claude Sonnet and other AI models: How do they compare?

In [Llama 3.1 research paper](https://ai.meta.com/blog/meta-Llama-3-1/), Meta's researchers compare the different models' performance on various benchmarks [multi-task language understanding](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu/)  and [ARC-challenge common snese logic test](https://paperswithcode.com/sota/common-sense-reasoning-on-arc-challenge)/) to a handful of equivalent open and proprietary models.

&mdash;The 8B model was compared to Mistral 7B and Gemma 2 9B;

&mdash;The 70B model was compared to GPT-3.5-Turbo and Mixtral 8x22B;

The evaluation showed that the smaller Llama models are competitive with closed and open models that have a similar number of parameters.

&mdash;The 405B model was compared with GPT-4, GPT-4o, and Claude 3.5 Sonnet

The evaluation was done on performance on over 150 benchmark datasets that span a wide range of languages. In addition, Meta performed extensive human evaluations that compare Llama 3.1 with competing models in real-world scenarios. This evaluation suggests that Llama 405B model is competitive with leading foundation models across a range of tasks, including GPT-4, GPT-4o, and Claude 3.5 Sonnet.


## Significance of Llama 

Most of the LLMs that exist today like OpenAI's GPT-4o ,Google's Gemini or Anthropic's Claude are proprietary and closed source. Developers and companies can access them by their model API’s, but you can’t understand what is going on inside, they will be “a black box” that can be used and fine-tuned for each company’s needs. 
Llama herd on the other hand is fully open, open-source technology and Meta has already published extensive details about how models were trained and the architecture they use.
Llama models can run on Microsoft Azure, Google Cloud, Amazon Web Services, and other cloud infrastructures so you can operate your own LLM-powered app or train it on your own data to generate the kind of text you need.


## Real-World Applications of Llama 3.1

Llama 3.1’s advanced capabilities make it suitable for a wide range of applications, from real-time and batch inference to supervised fine-tuning and continual pre-training. 
Some of the possible applications include:

•	Healthcare: Llama 3.1’s multilingual support and extended context length can assist physicians in clinical decision-making by providing detailed analysis and recommendations based on extensive medical literature and patient data. 

•	Education:  Llama 3.1 can serve as an intelligent tutor that offers personalized learning experiences to students by creating comprehensive study guides and providing detailed explanations on complex topics. 
•	Customer Service:  Llama 3.1 can be used as a conversational agent that understands and responds to customer inquiries in multiple languages, providing accurate and appropriate responses, while increasing productivity and customer satisfaction.

•	Synthetic Data Generation: Llama 3.1 has ability to generate high-quality synthetic data that can be used to train smaller models, perform simulations, and create datasets for various research purposes. 

•	Model Distillation: Llama 3.1 supports model distillation techniques, allowing developers to create smaller, more efficient models without sacrificing performance while allowing AI capabilities to be deployed on devices with limited computational resources.

•	Multilingual Conversational Agents: Llama 3.1 has support for eight languages which makes it ideal for building multilingual conversational agents; chatbots with complex human interactions and that provide accurate translations.


## Key Highlights of Llama 3.1

•	Massive Scale and Advanced Performance: The 405B version boasts 405 billion parameters and was trained on over 15 trillion tokens, delivering top-tier performance across various tasks.

•	Extended Context and Multilingual Capabilities: Llama 3.1 supports up to 128K tokens for comprehensive content generation and handles eight languages, enhancing global application versatility.

•	Innovative Features: Enables synthetic data generation and model distillation, allowing for the creation of efficient models and robust training datasets.

•	Comprehensive Ecosystem Support: Llama 3.1 is available for download on Meta’s platform and Hugging Face, with deployment options across cloud, on-premises, and local environments, supported by key industry partners.

•	Enhanced Safety and Community Collaboration: Llama 3.1 Includes new safety tools like Llama Guard 3 and Prompt Guard, with active support from community projects for optimized development and deployment.

## Conclusion &mdash;Why Open-Source AI Is Good for the World

In a letter accompanying [Llama 3.1 release](https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/), CEO Mark Zuckerberg confirmed Meta's plans to keep Llama open:

"I believe that open source is necessary for a positive AI future. AI has more potential than any other modern technology to increase human productivity, creativity, and quality of life—and to accelerate economic growth while unlocking progress in medical and scientific research. Open source will ensure that more people around the world have access to the benefits and opportunities of AI, that power isn't concentrated in the hands of a small number of companies, and that the technology can be deployed more evenly and safely across society."

Llama 3.1 open-source technology is game-changer in the world of generative AI.

With its advanced architecture, significant improvements in areas like reasoning, coding, multilingual capabilities with an impressive broad set of applicability, it's set to reshape industries like healthcare, customer service, and content creation. 

Llama 3.1 offers a glimpse into the future of AI, where machines understand and generate human language with unprecedented accuracy and efficiency.


## References
•	[Llama 3.1 research paper](https://ai.meta.com/blog/meta-Llama-3-1/)

•	[Path forward](https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/)

•	[Llama 3.1 explained](https://encord.com/blog/llama-3-1-explained/)

•	[Llama 3.1](https://zapier.com/blog/llama-meta/)

•	[Meta Llama 3.1](https://www.labellerr.com/blog/metas-llama-3-1/)



